{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "locked": true,
     "solution": false
    }
   },
   "source": [
    "## There are some instructions you need to follow:\n",
    "<li> You only need to write your code in the comment area \"Your Code Here\".</li>\n",
    "<li>Do not upload your own file. Please make the necessary changes in the Jupyter notebook file already present in the server.</li>\n",
    "<li>Please note, there are several cells in the Assignment Jupyter notebook that are empty and read only. Do not attempt to remove them or   edit them. They are used in grading your notebook. Doing so might lead to 0 points.</li>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "locked": true,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "import nltk\n",
    "import os\n",
    "import _sqlite3\n",
    "from nltk.corpus import PlaintextCorpusReader\n",
    "from nltk import sent_tokenize,word_tokenize \n",
    "from gensim import corpora, models, similarities\n",
    "from gensim.models.ldamodel import LdaModel\n",
    "from gensim.parsing.preprocessing import STOPWORDS\n",
    "from gensim.similarities.docsim import Similarity"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "locked": false,
     "solution": false
    }
   },
   "source": [
    "# Question 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Question 1\n",
    "\n",
    "Write a function that takes the file name of the Wikipedia page containing all Greek ancient\n",
    "philosophers (saved as \"Index.html\" in your workspace) and returns a list tuples containing \n",
    "the name of the philosopher and the path to its individual article file.\n",
    "\n",
    "Example of use: get_philosophers(\"Index.html\")\n",
    "\n",
    "The output should be a list of tuples:\n",
    "\n",
    "[('Acrion', 'Philosophers/Acrion.html'),\n",
    " ('Adrastus of Aphrodisias', 'Philosophers/Adrastus of Aphrodisias.html'),\n",
    " ('Aedesia', 'Philosophers/Aedesia.html'),\n",
    " ('Aedesius', 'Philosophers/Aedesius.html'),\n",
    " ('Aeneas of Gaza', 'Philosophers/Aeneas of Gaza.html'),\n",
    " ('Aenesidemus', 'Philosophers/Aenesidemus.html'),\n",
    " ...]\n",
    " \n",
    "  \n",
    "NOTE: For processing speed purposes, the table in \"Index.html\" has been shortened compared\n",
    "to the one online on wikipedia.org. Do not worry if you do not find some philosophers in \n",
    "your results, this is made on purpose. \n",
    "\n",
    "\"\"\"\n",
    "\n",
    "def get_philosophers(filename):\n",
    "    \n",
    "    import codecs\n",
    "    from bs4 import BeautifulSoup\n",
    "    f = codecs.open(filename, 'r', 'utf-8')\n",
    "    soup = BeautifulSoup(f.read(),'lxml')\n",
    "    \n",
    "    philosopher_list = []\n",
    "    \n",
    "    tableRows = soup.find_all('table',class_='wikitable sortable')[0]\n",
    "    data_rows = tableRows.find_all('tr')[1:]\n",
    "    philosopher_name = [] #list containing each philosopher's name\n",
    "    # grabs philosopher name from title an appends to list\n",
    "    for data in data_rows:\n",
    "        philosopher_name.append(data.find('a').get('title'))\n",
    "\n",
    "    # adding path and filename at the end of philosopher's name\n",
    "    for name in philosopher_name:\n",
    "        x = name\n",
    "        y = name,\"Philosophers/\"+ x + '.html'\n",
    "        philosopher_list.append(y)\n",
    "\n",
    "#   returns philosopher list as tuple\n",
    "#     philosopher_tuple_list = tuple(philosopher_list)\n",
    "    return philosopher_list\n",
    "\n",
    "# Once done, try this:\n",
    "# get_philosophers(\"Index.html\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Question 1: Non-Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "import codecs\n",
    "from bs4 import BeautifulSoup\n",
    "f = codecs.open(\"Index.html\", 'r', 'utf-8')\n",
    "soup = BeautifulSoup(f.read(),'lxml')\n",
    "\n",
    "# reference: http://savvastjortjoglou.com/nba-draft-part01-scraping.html\n",
    "# tuples of philosopher name w/ path \n",
    "philosopher_list = []\n",
    "\n",
    "# creates list of philosopher name\n",
    "tableRows = soup.find_all('table',class_='wikitable sortable')[0]\n",
    "data_rows = tableRows.find_all('tr')[1:]\n",
    "philosopher_name = [] #list containing each philosopher's name\n",
    "\n",
    "# grabs philosopher name from title and appends to list\n",
    "for data in data_rows:\n",
    "    philosopher_name.append(data.find('a').get('title'))\n",
    "#     print(type(data))\n",
    "\n",
    "\n",
    "# # loops through a list indices \n",
    "# for i in range(len(data_rows)):\n",
    "#     # for each table data element from each table row\n",
    "#     td = data_rows[i].find_all('td')[0].get_text().strip()\n",
    "# #     philosopher_name.append(td)\n",
    "\n",
    "\n",
    "# adding path and filename at the end of philosopher's name\n",
    "for name in philosopher_name:\n",
    "    x = name\n",
    "    y = name,\"Philosophers/\"+ x + '.html'\n",
    "    philosopher_list.append(y)\n",
    "\n",
    "# philosopher_list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "locked": true,
     "solution": false
    }
   },
   "source": [
    "# Question 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Question 2\n",
    "\n",
    "\n",
    "Write a function that scrapes the text on a philosophers’s page and returns it as a text \n",
    "string. The input is the name of the file that contains the philosopher's page.\n",
    "\n",
    "Example of use: get_text('Philosophers/Acrion.html')\n",
    "should output the text of the page.\n",
    "'Acrion was a Locrian and a Pythagorean philosopher...'\n",
    "\"\"\"\n",
    "\n",
    "def get_text(file):\n",
    "    import codecs\n",
    "    from bs4 import BeautifulSoup\n",
    "    f = codecs.open(file, 'r', 'utf-8')\n",
    "    page_soup = BeautifulSoup(f.read(),'lxml')\n",
    "\n",
    "    all_text = \"\"\n",
    "\n",
    "    for tag in page_soup.find_all('p'):\n",
    "        all_text += tag.get_text()\n",
    "    return all_text\n",
    "# Once done, try this:\n",
    "# get_text(\"Philosophers/Acrion.html\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Question 2: Non-Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# looks at page index.html (all philosophers)\n",
    "filename = \"Philosophers/Acrion.html\"\n",
    "\n",
    "import codecs\n",
    "from bs4 import BeautifulSoup\n",
    "f = codecs.open(filename, 'r', 'utf-8')\n",
    "page_soup = BeautifulSoup(f.read(),'lxml')\n",
    "\n",
    "\n",
    "all_text = \"\"\n",
    "\n",
    "# takes the 2nd index from list philosopher_list\n",
    "for philosopher_filepath in philosopher_list:\n",
    "    philosopher_filepath = philosopher_filepath[1]\n",
    "    \n",
    "    filepath = codecs.open(philosopher_filepath, 'r', 'utf-8')\n",
    "    page_soup = BeautifulSoup(filepath.read(),'lxml')\n",
    "    \n",
    "    for tag in page_soup.find_all('p'):\n",
    "        all_text += tag.get_text()\n",
    "# all_text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Question 3 (functional)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nQuestion 3\\n\\nUse the files under \"Philosophers\" folder to construct an LSI model.\\nThen, use the LSI model to find the most similar philosopher for each of the philosophers\\nfound in Question 1, based on the content of their Wikipedia articles. You should not go\\nonline to scrape the data; everything you need is in your Jupyter notebook working directory.\\n\\nThe function should have as input the list of tuples created in Question 1.\\n\\nThe output format should be a list of tuples too. Each tuple should contain a philosopher\\'s name\\nand its most similar other philosopher. Please note both names can\\'t be the same.\\n\\nThe output should look like that:\\n\\n[(\\'Acrion\\', \\'Arignote\\'),\\n (\\'Adrastus of Aphrodisias\\', \\'Lycophron (Sophist)\\'),\\n (\\'Aedesia\\', \\'Heliodorus of Alexandria\\'),\\n (\\'Aedesius\\', \\'Chrysanthius\\'),\\n (\\'Aeneas of Gaza\\', \\'Archytas\\'),\\n ...]\\n\\n\\n'"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "Question 3\n",
    "\n",
    "Use the files under \"Philosophers\" folder to construct an LSI model.\n",
    "Then, use the LSI model to find the most similar philosopher for each of the philosophers\n",
    "found in Question 1, based on the content of their Wikipedia articles. You should not go\n",
    "online to scrape the data; everything you need is in your Jupyter notebook working directory.\n",
    "\n",
    "The function should have as input the list of tuples created in Question 1.\n",
    "\n",
    "The output format should be a list of tuples too. Each tuple should contain a philosopher's name\n",
    "and its most similar other philosopher. Please note both names can't be the same.\n",
    "\n",
    "The output should look like that:\n",
    "\n",
    "[('Acrion', 'Arignote'),\n",
    " ('Adrastus of Aphrodisias', 'Lycophron (Sophist)'),\n",
    " ('Aedesia', 'Heliodorus of Alexandria'),\n",
    " ('Aedesius', 'Chrysanthius'),\n",
    " ('Aeneas of Gaza', 'Archytas'),\n",
    " ...]\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "# def run1(filenames):\n",
    "# ###\n",
    "# ### YOUR CODE HERE\n",
    "# ###\n",
    "\n",
    "# # Once done, try this:\n",
    "# run(filenames)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Question 3 (non-functional)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "import os\n",
    "import _sqlite3\n",
    "from nltk.corpus import PlaintextCorpusReader\n",
    "from nltk import sent_tokenize,word_tokenize \n",
    "from gensim import corpora, models, similarities\n",
    "from gensim.models.ldamodel import LdaModel\n",
    "from gensim.parsing.preprocessing import STOPWORDS\n",
    "from gensim.similarities.docsim import Similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2473"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# text preprocessing\n",
    "# all_text = scraped description of all philosophers\n",
    "striptext = all_text.replace('\\n\\n', ' ')\n",
    "striptext = striptext.replace('\\n', ' ')\n",
    "sentences = sent_tokenize(striptext)\n",
    "texts = [[word for word in sentence.lower().split()\n",
    "         if word not in STOPWORDS and word.isalnum()]\n",
    "         for sentence in sentences ]\n",
    "len(texts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create word dictionary for each word in a text \n",
    "dictionary = corpora.Dictionary(texts)\n",
    "\n",
    "# create corpus: assigns ints to words\n",
    "# https://radimrehurek.com/gensim/corpora/dictionary.html#gensim.corpora.dictionary.Dictionary.doc2bow\n",
    "# (token_id,token_count)\n",
    "corpus = [dictionary.doc2bow(text) for text in texts]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create LSI model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": true,
     "grade_id": "Scraping filenames",
     "locked": true,
     "points": "20",
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "###\n",
    "### AUTOGRADER TEST - DO NOT REMOVE\n",
    "###\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": true,
     "grade_id": "Text of page",
     "locked": true,
     "points": "20",
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "###\n",
    "### AUTOGRADER TEST - DO NOT REMOVE\n",
    "###\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": true,
     "grade_id": "Run LSI",
     "locked": true,
     "points": "60",
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "###\n",
    "### AUTOGRADER TEST - DO NOT REMOVE\n",
    "###\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
